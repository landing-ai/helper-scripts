{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert from YOLO to Pascal VOC\n",
    "\n",
    "This script processes YOLO annotations and converts them into the Pascal VOC format. It reads bounding boxes from YOLO-style .txt files, converts them to Pascal VOC format, and saves them in .xml files alongside the images.\n",
    "\n",
    "## Pascal VOC format for Object Detection with Landing Lens\n",
    "If you have labeled images you want to upload to Object Detection projects, you can upload them in the Pascal VOC (Visual Object Classes) format. This format involves uploading the original (unlabeled) image and a corresponding XML file. The XML file contains the label (annotation) details of its paired image. The XML file essentially tells LandingLens where each label is on its associated image and what the name of the class is.\n",
    "\n",
    "The image and XML file must have the same file name (with different extensions). For example:\n",
    "\n",
    "vehicle_123.png\n",
    "vehicle_123.xml\n",
    "\n",
    "Additional details at:\n",
    "https://support.landing.ai/docs/upload-labeled-images-od?highlight=pascal%20voc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import cv2\n",
    "from lxml import etree, objectify\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions\n",
    "\n",
    "### save_anno_to_xml()\n",
    "\n",
    "save_anno_to_xml(filename, size, objs, save_path)\n",
    "\n",
    "**Parameters:**\n",
    "* filename: The image filename.\n",
    "* size: The dimensions of the image (height, width, depth).\n",
    "* objs: A list of objects, each containing a category and bounding box coordinates.\n",
    "* save_path: The directory where the .xml files will be saved.\n",
    "\n",
    "Converts annotations into Pascal VOC .xml format and saves them. It uses the objectify.ElementMaker to generate XML elements and builds an XML tree with annotation details like the image name, size, and bounding box information.\n",
    "The resulting XML is saved with the same name as the image, but with a .xml extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_anno_to_xml(filename, size, objs, save_path):\n",
    "    E = objectify.ElementMaker(annotate=False)\n",
    "    anno_tree = E.annotation(\n",
    "        E.folder(\"DATA\"),\n",
    "        E.filename(filename),\n",
    "        E.source(\n",
    "            E.database(\"The VOC Database\"),\n",
    "            E.annotation(\"PASCAL VOC\"),\n",
    "            E.image(\"flickr\")\n",
    "        ),\n",
    "        E.size(\n",
    "            E.width(size[1]),\n",
    "            E.height(size[0]),\n",
    "            E.depth(size[2])\n",
    "        ),\n",
    "        E.segmented(0)\n",
    "    )\n",
    "    for obj in objs:\n",
    "        E2 = objectify.ElementMaker(annotate=False)\n",
    "        anno_tree2 = E2.object(\n",
    "            E.name(obj[0]),\n",
    "            E.pose(\"Unspecified\"),\n",
    "            E.truncated(0),\n",
    "            E.difficult(0),\n",
    "            E.bndbox(\n",
    "                E.xmin(obj[1][0]),\n",
    "                E.ymin(obj[1][1]),\n",
    "                E.xmax(obj[1][2]),\n",
    "                E.ymax(obj[1][3])\n",
    "            )\n",
    "        )\n",
    "        anno_tree.append(anno_tree2)\n",
    "    anno_path = os.path.join(save_path, filename[:-3] + \"xml\")\n",
    "    etree.ElementTree(anno_tree).write(anno_path, pretty_print=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xywhn2xyxy()\n",
    "\n",
    "xywhn2xyxy(bbox, size)\n",
    "\n",
    "**Parameters:**\n",
    "* bbox: A YOLO-format bounding box as (center_x, center_y, width, height), normalized to the image dimensions.\n",
    "* size: The actual dimensions of the image.\n",
    "\n",
    "Converts YOLO-format bounding boxes (center coordinates, width, height as normalized values) to Pascal VOC-style bounding boxes (xmin, ymin, xmax, ymax in pixel values). The function calculates the pixel positions of the bounding box edges and returns them as integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xywhn2xyxy(bbox, size):\n",
    "    bbox = list(map(float, bbox))\n",
    "    size = list(map(float, size))\n",
    "    xmin = (bbox[0] - bbox[2] / 2.) * size[1]\n",
    "    ymin = (bbox[1] - bbox[3] / 2.) * size[0]\n",
    "    xmax = (bbox[0] + bbox[2] / 2.) * size[1]\n",
    "    ymax = (bbox[1] + bbox[3] / 2.) * size[0]\n",
    "    box = [xmin, ymin, xmax, ymax]\n",
    "    return list(map(int, box))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parseXmlFilse()\n",
    "\n",
    "parseXmlFilse(image_path, anno_path, save_path)\n",
    "\n",
    "**Parameters**\n",
    "* image_path: Path to the folder containing images.\n",
    "* anno_path: Path to the folder containing YOLO-format .txt annotation files.\n",
    "* save_path: Path where the resulting Pascal VOC .xml files will be saved.\n",
    "\n",
    "The main function that processes the YOLO .txt annotation files, converts them to Pascal VOC .xml files, and saves them. Key steps are 1) reading the classes from classes.txt to build a category set, 2) Mapping each image file and its annotations, 3)\n",
    "iterating over each annotation file and reading the bounding box data, converting it to VOC format using xywhn2xyxy(), and 4)\n",
    "calling save_anno_to_xml() to save each annotation file as an XML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseXmlFilse(image_path, anno_path, save_path):\n",
    "    global images_nums, category_nums, bbox_nums\n",
    "    assert os.path.exists(image_path), \"ERROR {} dose not exists\".format(image_path)\n",
    "    assert os.path.exists(anno_path), \"ERROR {} dose not exists\".format(anno_path)\n",
    "    if os.path.exists(save_path):\n",
    "        shutil.rmtree(save_path)\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "    category_set = []\n",
    "    with open(anno_path + '/classes.txt', 'r') as f:\n",
    "        for i in f.readlines():\n",
    "            category_set.append(i.strip())\n",
    "    category_nums = len(category_set)\n",
    "    category_id = dict((k, v) for k, v in enumerate(category_set))\n",
    "\n",
    "    images = [os.path.join(image_path, i) for i in os.listdir(image_path)]\n",
    "    files = [os.path.join(anno_path, i) for i in os.listdir(anno_path)]\n",
    "    images_index = dict((v.split(os.sep)[-1][:-4], k) for k, v in enumerate(images))\n",
    "    images_nums = len(images)\n",
    "\n",
    "    for file in tqdm(files):\n",
    "        if os.path.splitext(file)[-1] != '.txt' or 'classes' in file.split(os.sep)[-1]:\n",
    "            continue\n",
    "        if file.split(os.sep)[-1][:-4] in images_index:\n",
    "            index = images_index[file.split(os.sep)[-1][:-4]]\n",
    "            img = cv2.imread(images[index])\n",
    "            shape = img.shape\n",
    "            filename = images[index].split(os.sep)[-1]\n",
    "        else:\n",
    "            continue\n",
    "        objects = []\n",
    "        with open(file, 'r') as fid:\n",
    "            for i in fid.readlines():\n",
    "                i = i.strip().split()\n",
    "                category = int(i[0])\n",
    "                category_name = category_id[category]\n",
    "                bbox = xywhn2xyxy((i[1], i[2], i[3], i[4]), shape)\n",
    "                obj = [category_name, bbox]\n",
    "                objects.append(obj)\n",
    "        bbox_nums += len(objects)\n",
    "        save_anno_to_xml(filename, shape, objects, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Block\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "* Parses command-line arguments using argparse for paths:\n",
    "--anno-path: Path to the YOLO .txt annotations.\n",
    "--save-path: Destination folder for the VOC .xml files.\n",
    "--image-path: Path to the images.\n",
    "* If no command-line arguments are provided, default paths are used.\n",
    "* After parsing the arguments, the script calls parseXmlFilse with the provided arguments or default paths to begin the conversion process.\n",
    "* Finally, it prints the total number of images, categories, and bounding boxes processed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_nums = 0\n",
    "category_nums = 0\n",
    "bbox_nums = 0\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \"\"\"\n",
    "    Script Description:\n",
    "        This script is used to convert annotation file .txt in yolo format to annotation file .xml in voc format\n",
    "    Parameter description:\n",
    "        anno_path:txt storage path of the annotation file.\n",
    "        save_path:the folder where the json file will be output.\n",
    "        image_path:path of the image.\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-ap', '--anno-path', type=str, default='./data/labels/yolo', help='yolo txt path')\n",
    "    parser.add_argument('-s', '--save-path', type=str, default='./data/convert/voc', help='xml save path')\n",
    "    parser.add_argument('--image-path', default='./data/images')\n",
    "\n",
    "    opt = parser.parse_args()\n",
    "    if len(sys.argv) > 1:\n",
    "        print(opt)\n",
    "        parseXmlFilse(**vars(opt))\n",
    "        print(\"image nums: {}\".format(images_nums))\n",
    "        print(\"category nums: {}\".format(category_nums))\n",
    "        print(\"bbox nums: {}\".format(bbox_nums))\n",
    "    else:\n",
    "        anno_path = './data/labels/yolo'\n",
    "        save_path = './data/convert/voc1'\n",
    "        image_path = './data/images'\n",
    "        parseXmlFilse(image_path, anno_path, save_path)\n",
    "        print(\"image nums: {}\".format(images_nums))\n",
    "        print(\"category nums: {}\".format(category_nums))\n",
    "        print(\"bbox nums: {}\".format(bbox_nums))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
