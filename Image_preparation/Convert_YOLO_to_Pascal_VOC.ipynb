{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert from YOLO to Pascal VOC\n",
    "\n",
    "This script processes YOLO annotations and converts them into the Pascal VOC format. It reads bounding boxes from YOLO-style .txt files, converts them to Pascal VOC format, and saves them in .xml files alongside the images.\n",
    "\n",
    "## Pascal VOC format for Object Detection with Landing Lens\n",
    "If you have labeled images you want to upload to Object Detection projects, you can upload them in the Pascal VOC (Visual Object Classes) format. This format involves uploading the original (unlabeled) image and a corresponding XML file. The XML file contains the label (annotation) details of its paired image. The XML file essentially tells LandingLens where each label is on its associated image and what the name of the class is.\n",
    "\n",
    "The image and XML file must have the same file name (with different extensions). For example:\n",
    "\n",
    "* vehicle_123.png\n",
    "* vehicle_123.xml\n",
    "\n",
    "Additional details at:\n",
    "https://support.landing.ai/docs/upload-labeled-images-od?highlight=pascal%20voc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import cv2\n",
    "from lxml import etree, objectify\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from lxml import etree, objectify\n",
    "\n",
    "def save_anno_to_xml(filename, size, objs, save_path):\n",
    "    \"\"\"\n",
    "    Save object annotation data to an XML file in Pascal VOC format.\n",
    "\n",
    "    This function generates an XML file containing annotations for objects \n",
    "    in an image, including the size of the image and bounding boxes for \n",
    "    each object, and saves it to the specified path.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    filename : str\n",
    "        The name of the image file (e.g., 'image.jpg').\n",
    "    size : tuple\n",
    "        A tuple representing the size of the image as (height, width, depth).\n",
    "    objs : list of tuples\n",
    "        A list of objects to annotate, where each object is represented as a \n",
    "        tuple: (class_name, (xmin, ymin, xmax, ymax)). Each object specifies \n",
    "        the class name and the bounding box coordinates.\n",
    "    save_path : str\n",
    "        The directory where the generated XML file will be saved.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    None\n",
    "        This function saves the XML file to the specified path but does not \n",
    "        return anything.\n",
    "\n",
    "    Raises:\n",
    "    -------\n",
    "    OSError:\n",
    "        If there is an error writing to the specified path.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the root XML tree using ElementMaker for the annotation.\n",
    "    E = objectify.ElementMaker(annotate=False)\n",
    "    anno_tree = E.annotation(\n",
    "        E.folder(\"DATA\"),\n",
    "        E.filename(filename),\n",
    "        E.source(\n",
    "            E.database(\"The VOC Database\"),\n",
    "            E.annotation(\"PASCAL VOC\"),\n",
    "            E.image(\"flickr\")\n",
    "        ),\n",
    "        E.size(\n",
    "            E.width(size[1]), # Width of the image\n",
    "            E.height(size[0]), # Height of the image\n",
    "            E.depth(size[2]) # Depth of the image (e.g., 3 for RGB)\n",
    "        ),\n",
    "        E.segmented(0) # Set 'segmented' to 0 (no segmentation by default)\n",
    "    )\n",
    "\n",
    "    # Iterate over each object in the list and add its annotation to the XML tree.\n",
    "    for obj in objs:\n",
    "        E2 = objectify.ElementMaker(annotate=False)\n",
    "        anno_tree2 = E2.object(\n",
    "            E.name(obj[0]), # Object class name (e.g., 'cat', 'dog')\n",
    "            E.pose(\"Unspecified\"), # Pose of the object (can be extended if needed)\n",
    "            E.truncated(0), # Truncated flag (0 means the object is not truncated)\n",
    "            E.difficult(0), # Difficulty flag (0 means the object is not difficult to detect)\n",
    "            E.bndbox(\n",
    "                E.xmin(obj[1][0]), # Bounding box left x-coordinate (xmin)\n",
    "                E.ymin(obj[1][1]), # Bounding box top y-coordinate (ymin)\n",
    "                E.xmax(obj[1][2]), # Bounding box right x-coordinate (xmax)\n",
    "                E.ymax(obj[1][3]) # Bounding box bottom y-coordinate (ymax)\n",
    "            )\n",
    "        )\n",
    "        # Append the object annotation to the main annotation tree.\n",
    "        anno_tree.append(anno_tree2)\n",
    "\n",
    "    # Define the full file path where the XML will be saved, replacing the image extension with '.xml'.    \n",
    "    anno_path = os.path.join(save_path, filename[:-3] + \"xml\")\n",
    "\n",
    "    # Write the XML tree to the specified path with pretty formatting.\n",
    "    etree.ElementTree(anno_tree).write(anno_path, pretty_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "def xywhn2xyxy(bbox, size):\n",
    "    \"\"\"\n",
    "    Convert a bounding box from normalized (x_center, y_center, width, height) \n",
    "    format to absolute (xmin, ymin, xmax, ymax) format.\n",
    "\n",
    "    This function takes a bounding box in normalized coordinates, where the box is \n",
    "    represented by its center point (x_center, y_center) and its width and height, \n",
    "    and converts it to absolute pixel coordinates based on the image size.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    bbox : list or tuple\n",
    "        A list or tuple representing the bounding box in normalized coordinates as \n",
    "        (x_center, y_center, width, height), where all values are relative to the image \n",
    "        size (ranging from 0 to 1).\n",
    "    size : list or tuple\n",
    "        A list or tuple representing the image size as (height, width).\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    list\n",
    "        A list of integers representing the bounding box in absolute pixel coordinates \n",
    "        as [xmin, ymin, xmax, ymax].\n",
    "    \n",
    "    Example:\n",
    "    --------\n",
    "    >>> xywhn2xyxy([0.5, 0.5, 0.2, 0.4], [1000, 2000])\n",
    "    [900, 300, 1100, 700]\n",
    "    \n",
    "    This converts a normalized bounding box (centered at 50% width, 50% height, \n",
    "    with width 20% and height 40%) into pixel coordinates based on a 1000x2000 image.  \n",
    "    \"\"\"\n",
    "\n",
    "    # Convert bbox and size to floats to ensure precision for calculations.\n",
    "    bbox = list(map(float, bbox))\n",
    "    size = list(map(float, size))\n",
    "\n",
    "    # Compute xmin and ymin: the top-left corner of the bounding box.\n",
    "    xmin = (bbox[0] - bbox[2] / 2.) * size[1]\n",
    "    ymin = (bbox[1] - bbox[3] / 2.) * size[0]\n",
    "\n",
    "    # Compute xmax and ymax: the bottom-right corner of the bounding box.\n",
    "    xmax = (bbox[0] + bbox[2] / 2.) * size[1]\n",
    "    ymax = (bbox[1] + bbox[3] / 2.) * size[0]\n",
    "\n",
    "    # Create the box as [xmin, ymin, xmax, ymax] and convert to integers.\n",
    "    box = [xmin, ymin, xmax, ymax]\n",
    "\n",
    "    # Return the bounding box coordinates as integers.\n",
    "    return list(map(int, box))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseXmlFilse(image_path, anno_path, save_path):\n",
    "    \"\"\"\n",
    "    Parse image and annotation files, convert bounding box coordinates,\n",
    "    and save them in XML format for object detection datasets.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the directory containing image files.\n",
    "        anno_path (str): Path to the directory containing annotation files.\n",
    "        save_path (str): Path where the parsed XML files will be saved.\n",
    "\n",
    "    Global Variables:\n",
    "        images_nums (int): Total number of image files processed.\n",
    "        category_nums (int): Total number of unique categories.\n",
    "        bbox_nums (int): Total number of bounding boxes processed.\n",
    "\n",
    "    Raises:\n",
    "        AssertionError: If the image_path or anno_path does not exist.\n",
    "\n",
    "    Description:\n",
    "        This function parses a set of images and their corresponding annotations. It reads\n",
    "        the image files from the image_path and annotation files from the anno_path. It\n",
    "        matches the annotation with the corresponding image, converts bounding box\n",
    "        coordinates from normalized format (xywhn) to absolute coordinates (xyxy), and\n",
    "        saves the results in XML format to the specified save_path.\n",
    "    \"\"\"\n",
    "    # Declare global variables to track totals\n",
    "    global images_nums, category_nums, bbox_nums\n",
    "\n",
    "    # Check if image and annotation paths exist\n",
    "    assert os.path.exists(image_path), \"ERROR {} dose not exists\".format(image_path)\n",
    "    assert os.path.exists(anno_path), \"ERROR {} dose not exists\".format(anno_path)\n",
    "\n",
    "    # Remove the existing save directory if it exists and create a new one\n",
    "    if os.path.exists(save_path):\n",
    "        shutil.rmtree(save_path)\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "    # Initialize category list and load class names from 'classes.txt'\n",
    "    category_set = []\n",
    "    with open(anno_path + '/classes.txt', 'r') as f:\n",
    "        for i in f.readlines():\n",
    "            category_set.append(i.strip())\n",
    "    category_nums = len(category_set) # Count the number of unique categories\n",
    "    \n",
    "    # Create a dictionary that maps class indices to category names\n",
    "    category_id = dict((k, v) for k, v in enumerate(category_set))\n",
    "\n",
    "    # Get a list of images and annotations\n",
    "    images = [os.path.join(image_path, i) for i in os.listdir(image_path)]\n",
    "    files = [os.path.join(anno_path, i) for i in os.listdir(anno_path)]\n",
    "    \n",
    "    # Create a dictionary mapping image file names (without extension) to their index\n",
    "    images_index = dict((v.split(os.sep)[-1][:-4], k) for k, v in enumerate(images))\n",
    "    images_nums = len(images)\n",
    "\n",
    "    # Loop through all annotation files\n",
    "    for file in tqdm(files):\n",
    "        # Skip non-txt files or the 'classes.txt' file\n",
    "        if os.path.splitext(file)[-1] != '.txt' or 'classes' in file.split(os.sep)[-1]:\n",
    "            continue\n",
    "        \n",
    "        # Check if the annotation corresponds to an existing image\n",
    "        if file.split(os.sep)[-1][:-4] in images_index:\n",
    "            index = images_index[file.split(os.sep)[-1][:-4]]\n",
    "            img = cv2.imread(images[index]) # Read the corresponding image\n",
    "            shape = img.shape # Get image dimensions (height, width, channels)\n",
    "            filename = images[index].split(os.sep)[-1] # Get the image file name\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        objects = []\n",
    "        # Open the annotation file and read each bounding box entry\n",
    "        with open(file, 'r') as fid:\n",
    "            for i in fid.readlines():\n",
    "                i = i.strip().split() # Split the line by whitespace\n",
    "                category = int(i[0]) # Extract the category (class index)\n",
    "                category_name = category_id[category] # Get the category name\n",
    "                bbox = xywhn2xyxy((i[1], i[2], i[3], i[4]), shape) # Convert bounding box format\n",
    "                obj = [category_name, bbox] # Store the object as [category, bbox]\n",
    "                objects.append(obj) # Add the object to the list\n",
    "        \n",
    "        # Update the total number of bounding boxes processed\n",
    "        bbox_nums += len(objects)\n",
    "        \n",
    "        # Save the annotations and bounding boxes to an XML file\n",
    "        save_anno_to_xml(filename, shape, objects, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Block\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "* Parses command-line arguments using argparse for paths:\n",
    "--anno-path: Path to the YOLO .txt annotations.\n",
    "--save-path: Destination folder for the VOC .xml files.\n",
    "--image-path: Path to the images.\n",
    "* If no command-line arguments are provided, default paths are used.\n",
    "* After parsing the arguments, the script calls parseXmlFilse with the provided arguments or default paths to begin the conversion process.\n",
    "* Finally, it prints the total number of images, categories, and bounding boxes processed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "\n",
    "# Initialize global counters\n",
    "images_nums = 0\n",
    "category_nums = 0\n",
    "bbox_nums = 0\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \"\"\"\n",
    "    Script Description:\n",
    "        This script converts YOLO format annotation files (.txt) to VOC format annotation files (.xml).\n",
    "        \n",
    "    Parameters:\n",
    "        - anno_path (str): Path to the directory containing YOLO annotation files in .txt format.\n",
    "        - save_path (str): Directory where the converted VOC .xml files will be saved.\n",
    "        - image_path (str): Directory containing the corresponding image files.\n",
    "\n",
    "    Usage:\n",
    "        The script can be run with or without command-line arguments.\n",
    "        If no arguments are provided, default paths will be used for image and annotation files.\n",
    "\n",
    "    Example:\n",
    "        python script_name.py --anno-path ./data/labels/yolo --save-path ./data/convert/voc --image-path ./data/images\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set up the argument parser for command-line inputs\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-ap', '--anno-path', type=str, default='./data/labels/yolo', help='yolo txt path')\n",
    "    parser.add_argument('-s', '--save-path', type=str, default='./data/convert/voc', help='xml save path')\n",
    "    parser.add_argument('--image-path', default='./data/images')\n",
    "\n",
    "    # Parse the command-line arguments\n",
    "    opt = parser.parse_args()\n",
    "\n",
    "    # If arguments are provided via the command line, use them\n",
    "    if len(sys.argv) > 1:\n",
    "        print(opt) # Print the parsed options for debugging\n",
    "        parseXmlFilse(**vars(opt)) # Call the function using the parsed arguments\n",
    "        # Print global counters showing the total processed images, categories, and bounding boxes\n",
    "        print(\"image nums: {}\".format(images_nums))\n",
    "        print(\"category nums: {}\".format(category_nums))\n",
    "        print(\"bbox nums: {}\".format(bbox_nums))\n",
    "    else:\n",
    "        # Default paths if no command-line arguments are provided\n",
    "        anno_path = './data/labels/yolo'\n",
    "        save_path = './data/convert/voc1'\n",
    "        image_path = './data/images'\n",
    "\n",
    "        # Call the function with the default paths\n",
    "        parseXmlFilse(image_path, anno_path, save_path)\n",
    "\n",
    "        # Print the global counters after processing\n",
    "        print(\"image nums: {}\".format(images_nums))\n",
    "        print(\"category nums: {}\".format(category_nums))\n",
    "        print(\"bbox nums: {}\".format(bbox_nums))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
